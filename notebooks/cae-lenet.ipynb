{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from notebooks.bootstrap_notebooks import bootstrap_notebook, load_dataset, train, test\n",
    "from src.base.training.models.architectures.cae_lenet import CaeLeNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "EXP_NAME = \"cae_lenet_nb\"\n",
    "\n",
    "config = {\n",
    "    \"exp_name\": EXP_NAME,\n",
    "    \"enable_gpu\": True,\n",
    "    \"training_n_dev\": 1,\n",
    "    \"logs\": \"C:\\\\Users\\\\micdu\\\\Code\\\\pythonProject\\\\dmtl\\\\notebooks\\\\logs\",\n",
    "    \"training_out\": \"C:\\\\Users\\\\micdu\\\\Code\\\\pythonProject\\\\notebooks\\\\lightning_data\",\n",
    "    \"tracking_uri\": \"http://localhost:5000\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "bootstrap_notebook(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "load_dataset({\n",
    "    \"dataset\": \"mnist\",\n",
    "    \"data_path\": \"C:\\\\Users\\\\micdu\\\\Code\\\\pythonProject\\\\dmtl\\\\data\",\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m CaeLeNet()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Code\\pythonProject\\dmtl\\notebooks\\bootstrap_notebooks.py:56\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, epochs)\u001B[0m\n\u001B[0;32m     49\u001B[0m exp \u001B[38;5;241m=\u001B[39m Experiment(\n\u001B[0;32m     50\u001B[0m     state\u001B[38;5;241m.\u001B[39mget_module_state(CONFIG_MODULE)\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexp_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m     53\u001B[0m     model\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[0;32m     54\u001B[0m     model)\n\u001B[0;32m     55\u001B[0m tc \u001B[38;5;241m=\u001B[39m get_training_client(state)\n\u001B[1;32m---> 56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Code\\pythonProject\\dmtl\\src\\base\\training\\training_client.py:89\u001B[0m, in \u001B[0;36mTrainingClient.train_model\u001B[1;34m(self, exp, max_epochs)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_model\u001B[39m(\u001B[38;5;28mself\u001B[39m, exp: Experiment, max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Experiment:\n\u001B[0;32m     88\u001B[0m     train_loader, val_loader, tags \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_train_dataloader()\n\u001B[1;32m---> 89\u001B[0m     trainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_trainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_tags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mfit(exp\u001B[38;5;241m.\u001B[39mmodel, train_loader, val_loader)\n\u001B[0;32m     91\u001B[0m     exp\u001B[38;5;241m.\u001B[39mexperiment_id \u001B[38;5;241m=\u001B[39m exp\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mexperiment_id\n",
      "File \u001B[1;32m~\\Code\\pythonProject\\dmtl\\src\\base\\training\\training_client.py:66\u001B[0m, in \u001B[0;36mTrainingClient.get_trainer\u001B[1;34m(self, model, test, extra_tags, max_epochs)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_trainer\u001B[39m(\u001B[38;5;28mself\u001B[39m, model: Experiment, test\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, extra_tags\u001B[38;5;241m=\u001B[39m{}, max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# to early stop callbacks=[EarlyStopping(monitor=\"validation_loss\", mode=\"max\")],\u001B[39;00m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menable_gpu:\n\u001B[0;32m     61\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m pl\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[0;32m     62\u001B[0m             default_root_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_output_dir(),\n\u001B[0;32m     63\u001B[0m             accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     64\u001B[0m             auto_select_gpus\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     65\u001B[0m             auto_scale_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinsearch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m---> 66\u001B[0m             logger\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_logger\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_tags\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     67\u001B[0m             fast_dev_run\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfast_dev_run,\n\u001B[0;32m     68\u001B[0m             profiler\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprofiler,\n\u001B[0;32m     69\u001B[0m             max_epochs\u001B[38;5;241m=\u001B[39mmax_epochs \u001B[38;5;28;01mif\u001B[39;00m max_epochs \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs,\n\u001B[0;32m     70\u001B[0m             enable_progress_bar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     71\u001B[0m         )\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pl\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[0;32m     73\u001B[0m         default_root_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_output_dir(),\n\u001B[0;32m     74\u001B[0m         accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     81\u001B[0m         enable_progress_bar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     )\n",
      "File \u001B[1;32m~\\Code\\pythonProject\\dmtl\\src\\base\\training\\training_client.py:51\u001B[0m, in \u001B[0;36mTrainingClient.get_logger\u001B[1;34m(self, model, test, extra_tags)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m extra_tags\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     50\u001B[0m     tags[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(value)\n\u001B[1;32m---> 51\u001B[0m mlf_logger \u001B[38;5;241m=\u001B[39m \u001B[43mMLFlowLogger\u001B[49m(\n\u001B[0;32m     52\u001B[0m     experiment_name\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mexp_name,\n\u001B[0;32m     53\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[0;32m     54\u001B[0m     tracking_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracking_uri,\n\u001B[0;32m     55\u001B[0m )\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mlf_logger\n",
      "File \u001B[1;32m~\\Code\\pythonProject\\dmtl\\src\\base\\training\\training_client.py:51\u001B[0m, in \u001B[0;36mTrainingClient.get_logger\u001B[1;34m(self, model, test, extra_tags)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m extra_tags\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m     50\u001B[0m     tags[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(value)\n\u001B[1;32m---> 51\u001B[0m mlf_logger \u001B[38;5;241m=\u001B[39m \u001B[43mMLFlowLogger\u001B[49m(\n\u001B[0;32m     52\u001B[0m     experiment_name\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mexp_name,\n\u001B[0;32m     53\u001B[0m     tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[0;32m     54\u001B[0m     tracking_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtracking_uri,\n\u001B[0;32m     55\u001B[0m )\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mlf_logger\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.1.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1155\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1152\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.1.2\\plugins\\python\\helpers\\pydev\\pydevd.py:1170\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1167\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1170\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = CaeLeNet()\n",
    "train(model, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f184ee2470794aeea90e81a86cff3038"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_loss           0.11314120143651962\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "<src.base.training.models.experiment.Experiment at 0x29fffb03fd0>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "load_dataset({\n",
    "    \"dataset\": \"fmnist\",\n",
    "    \"data_path\": \"C:\\\\Users\\\\micdu\\\\Code\\\\pythonProject\\\\dmtl\\\\data\",\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 2.0 K \n",
      "1 | decoder | Sequential | 2.0 K \n",
      "---------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc16663c5f774923892b894edd903e88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "354a22ba83784ed3a7aea4c0c382d92c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "<src.base.training.models.experiment.Experiment at 0x29fdfca4d60>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fmnist_model = CaeLeNet()\n",
    "train(fmnist_model, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "217b64ceb06c4157878927bd319d9d8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_loss           0.03406978398561478\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "<src.base.training.models.experiment.Experiment at 0x29fb2c11ca0>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(fmnist_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "load_dataset({\n",
    "    \"dataset\": \"emnist\",\n",
    "    \"data_path\": \"C:\\\\Users\\\\micdu\\\\Code\\\\pythonProject\\\\dmtl\\\\data\",\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 2.0 K \n",
      "1 | decoder | Sequential | 2.0 K \n",
      "---------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a496952b7b1544b3a78178aadfc34b71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\micdu\\Code\\pythonProject\\dmtl\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0635d3033d0e45efb7e6b854f1b4c26c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c03e547ccdf4801a6d8f74f57e2bf8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa74006ac5854b199db791161e8c3439"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8efd349baefe4258b1b387f03c4c0d81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d90074c2a9647379d7b72e06b09a86b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2673353dce194bd9801e15233de413e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb6cb4fc00c14cbe8c2aceab8165c245"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69dd5deb3615444696734da6b89ac87f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "105b7bb77bed4c24a9a65805d69cc227"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b670c464640043c0bf4dd67e4ba172db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "400d430fe2e04f1abc8877b92b12b9a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<src.base.training.models.experiment.Experiment at 0x29fb0894520>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emnist_model = CaeLeNet()\n",
    "train(emnist_model, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49a3d6c3ca204042b7081ded3735f9dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_loss           0.00213300297036767\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "<src.base.training.models.experiment.Experiment at 0x29fb2c4b7f0>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(emnist_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}