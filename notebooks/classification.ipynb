{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "from src.base.training.models.architectures.lenet import LeNet\n",
    "from src.base.training.models.architectures.lenet_light import LeNetLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:\\\\Users\\\\micdu\\\\Code\\\\pythonProject\\\\dmtl\\\\data\"\n",
    "\n",
    "def load_samples(dataset_fn, n_samples, train=True):\n",
    "    dataset = dataset_fn(\n",
    "        DATA_PATH,\n",
    "        train=train,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=n_samples)\n",
    "    return next(iter(loader))\n",
    "\n",
    "def shuffle(x, y):\n",
    "    shuffle_index = torch.randperm(x.shape[0])\n",
    "    return x[shuffle_index], y[shuffle_index]\n",
    "\n",
    "def load_model(model_fn, path):\n",
    "    model = model_fn()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def use_models(x, model_fn, paths):\n",
    "    x_out = load_model(model_fn, paths[0])(x)\n",
    "    for path in paths[1:]:\n",
    "        model = load_model(model_fn, path)\n",
    "        x_out = torch.cat((x_out, model(x)), dim=1)\n",
    "    return x_out\n",
    "\n",
    "def load_and_prepare(n_samples=100, train=True, model_fn=LeNet):\n",
    "    mnist_x, mnist_y = load_samples(datasets.MNIST, n_samples, train=train)\n",
    "    x, y = shuffle(mnist_x, mnist_y)\n",
    "    x_out = use_models(x, model_fn, [\n",
    "        \"models/daeclust_07/6254e814cad034bdf8068d43f347bd6ac5195d7825c8a89469f5c3ecb00e6684/final_model.state\",\n",
    "        \"models/daeclust_07/bc921caf11e52a378db890398a1362e799a8a6a96f8d7f31038bd2d03a3ab7d0/final_model.state\",\n",
    "        \"models/daeclust_07/d018ae7db86692ad7df89f6b3d85848cb5277c2aae418b1270b96508b4cfdbf8/final_model.state\"\n",
    "    ])\n",
    "    return x_out.detach().numpy(), y.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6934782608695652,\n",
       "  'recall': 0.9300291545189504,\n",
       "  'f1-score': 0.7945205479452054,\n",
       "  'support': 343},\n",
       " '1': {'precision': 0.8774080560420315,\n",
       "  'recall': 0.9728155339805825,\n",
       "  'f1-score': 0.9226519337016574,\n",
       "  'support': 515},\n",
       " '2': {'precision': 0.07735849056603773,\n",
       "  'recall': 0.803921568627451,\n",
       "  'f1-score': 0.14113597246127366,\n",
       "  'support': 51},\n",
       " '3': {'precision': 0.992,\n",
       "  'recall': 0.2848937392303274,\n",
       "  'f1-score': 0.44265952699687633,\n",
       "  'support': 1741},\n",
       " '4': {'precision': 1.0,\n",
       "  'recall': 0.5015045135406219,\n",
       "  'f1-score': 0.6680026720106881,\n",
       "  'support': 997},\n",
       " '5': {'precision': 0.9824561403508771,\n",
       "  'recall': 0.5108323831242874,\n",
       "  'f1-score': 0.6721680420105026,\n",
       "  'support': 877},\n",
       " '6': {'precision': 0.31601731601731603,\n",
       "  'recall': 0.9733333333333334,\n",
       "  'f1-score': 0.477124183006536,\n",
       "  'support': 150},\n",
       " '7': {'precision': 0.181640625,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.3074380165289256,\n",
       "  'support': 93},\n",
       " '8': {'precision': 0.081799591002045,\n",
       "  'recall': 0.975609756097561,\n",
       "  'f1-score': 0.15094339622641512,\n",
       "  'support': 41},\n",
       " '9': {'precision': 0.36923076923076925,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.5393258426966292,\n",
       "  'support': 192},\n",
       " 'accuracy': 0.5552,\n",
       " 'macro avg': {'precision': 0.5571389249078642,\n",
       "  'recall': 0.7952939982453116,\n",
       "  'f1-score': 0.5115970133584711,\n",
       "  'support': 5000},\n",
       " 'weighted avg': {'precision': 0.8835801553794966,\n",
       "  'recall': 0.5552,\n",
       "  'f1-score': 0.5981888211535438,\n",
       "  'support': 5000}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = load_and_prepare(model_fn=LeNet, n_samples=5000, train=False)\n",
    "\n",
    "predictions_argmax = np.argmax(x_test, axis=1) % 10\n",
    "classification_report(predictions_argmax, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.9567780e+00, -2.9694698e+00, -2.9771998e+00, -3.4705944e+00,\n",
       "       -3.4944117e+00, -3.5562758e+00, -2.5571110e+00, -1.4094365e+00,\n",
       "       -1.3593700e+00, -1.7310058e+00, -3.4170986e+01, -3.4157955e+01,\n",
       "       -3.4088192e+01,  0.0000000e+00, -1.8760986e+01, -1.9427149e+01,\n",
       "       -2.8975773e+01, -2.9635868e+01, -2.9866068e+01, -2.9558195e+01,\n",
       "       -8.2453241e+00, -4.4450626e+00, -1.2474253e-02, -1.1553190e+01,\n",
       "       -1.1525580e+01, -1.1462899e+01, -9.3638458e+00, -9.2379446e+00,\n",
       "       -9.2419968e+00, -9.3391886e+00], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.9567780e+00, -2.9694698e+00, -2.9771998e+00, -3.4705944e+00,\n",
       "        -3.4944117e+00, -3.5562758e+00, -2.5571110e+00, -1.4094365e+00,\n",
       "        -1.3593700e+00, -1.7310058e+00],\n",
       "       [-3.4170986e+01, -3.4157955e+01, -3.4088192e+01,  0.0000000e+00,\n",
       "        -1.8760986e+01, -1.9427149e+01, -2.8975773e+01, -2.9635868e+01,\n",
       "        -2.9866068e+01, -2.9558195e+01],\n",
       "       [-8.2453241e+00, -4.4450626e+00, -1.2474253e-02, -1.1553190e+01,\n",
       "        -1.1525580e+01, -1.1462899e+01, -9.3638458e+00, -9.2379446e+00,\n",
       "        -9.2419968e+00, -9.3391886e+00]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(x_test, (-1, 3, 10))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.4282608695652174,\n",
       "  'recall': 0.9704433497536946,\n",
       "  'f1-score': 0.5942684766214178,\n",
       "  'support': 203},\n",
       " '1': {'precision': 0.7740805604203153,\n",
       "  'recall': 0.9888143176733781,\n",
       "  'f1-score': 0.868369351669941,\n",
       "  'support': 447},\n",
       " '2': {'precision': 0.013207547169811321,\n",
       "  'recall': 0.875,\n",
       "  'f1-score': 0.026022304832713755,\n",
       "  'support': 8},\n",
       " '3': {'precision': 0.994,\n",
       "  'recall': 0.27010869565217394,\n",
       "  'f1-score': 0.42478632478632483,\n",
       "  'support': 1840},\n",
       " '4': {'precision': 1.0,\n",
       "  'recall': 0.4314063848144953,\n",
       "  'f1-score': 0.6027727546714888,\n",
       "  'support': 1159},\n",
       " '5': {'precision': 0.9868421052631579,\n",
       "  'recall': 0.45546558704453444,\n",
       "  'f1-score': 0.6232686980609419,\n",
       "  'support': 988},\n",
       " '6': {'precision': 0.30735930735930733,\n",
       "  'recall': 0.9793103448275862,\n",
       "  'f1-score': 0.46787479406919275,\n",
       "  'support': 145},\n",
       " '7': {'precision': 0.19921875,\n",
       "  'recall': 0.9902912621359223,\n",
       "  'f1-score': 0.3317073170731707,\n",
       "  'support': 103},\n",
       " '8': {'precision': 0.0408997955010225,\n",
       "  'recall': 0.9523809523809523,\n",
       "  'f1-score': 0.0784313725490196,\n",
       "  'support': 21},\n",
       " '9': {'precision': 0.16538461538461538,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.2838283828382838,\n",
       "  'support': 86},\n",
       " 'accuracy': 0.4886,\n",
       " 'macro avg': {'precision': 0.49092535506634477,\n",
       "  'recall': 0.7913220894282738,\n",
       "  'f1-score': 0.43013297771724945,\n",
       "  'support': 5000},\n",
       " 'weighted avg': {'precision': 0.8952370461705353,\n",
       "  'recall': 0.4886,\n",
       "  'f1-score': 0.5466159423781536,\n",
       "  'support': 5000}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sum = np.argmax(np.sum(np.reshape(x_test, (-1, 3, 10)), axis=1), axis=1)\n",
    "classification_report(pred_sum, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def use_pca(x_train, y_train, x_test, y_test, train_test_fn, n_components=15):\n",
    "    if isinstance(n_components, int) and n_components > 0:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train = pca.fit_transform(x_train, y_train)\n",
    "        x_test = pca.transform(x_test)\n",
    "    return train_test_fn(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_decision_tree(x_train, y_train, x_test, y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=25)\n",
    "    decision_tree = decision_tree.fit(x_train, y_train)\n",
    "    tree_pred = decision_tree.predict(x_test)\n",
    "    return classification_report(tree_pred, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_svm(x, y, x_test, y_test):\n",
    "    # LinearSVC, ovo, ovr\n",
    "    svm_clf = svm.SVC()\n",
    "    svm_clf.fit(x, y)\n",
    "    svm_pred = svm_clf.predict(x_test)\n",
    "    return classification_report(svm_pred, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "def train_test_gnb(x, y, x_test, y_test):\n",
    "    gnb = GaussianNB()\n",
    "    gnb = gnb.fit(x, y)\n",
    "    gnb_pred = gnb.predict(x_test)\n",
    "    return classification_report(gnb_pred, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/neighbors.html\n",
    "def train_test_neighbors(x_train, y_train, x_test, y_test):\n",
    "    nca = NeighborhoodComponentsAnalysis(random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    nca_pipe = Pipeline([('nca', nca), ('knn', knn)])\n",
    "    nca_pipe.fit(x_train, y_train)\n",
    "    nca_knn_preds = nca_pipe.predict(x_test)\n",
    "    return classification_report(nca_knn_preds, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_random_forest(x_train, y_train, x_test, y_test):\n",
    "    rnd_forest = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "    rnd_forest.fit(x_train, y_train)\n",
    "    forest_pred = rnd_forest.predict(x_test)\n",
    "    return classification_report(forest_pred, y_test, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_test(n_samples, train_test_fn):\n",
    "    x_train, y_train = load_and_prepare(model_fn=LeNet, n_samples=n_samples, train=True)\n",
    "    x_test, y_test = load_and_prepare(model_fn=LeNet, n_samples=5000, train=False)\n",
    "    results = []\n",
    "    result = train_test_fn(x_train, y_train, x_test, y_test)\n",
    "    result[\"pca\"] = 0\n",
    "    result[\"n_samples\"] = n_samples\n",
    "    result[\"classifier\"] = train_test_fn.__name__\n",
    "    results.append(result)\n",
    "    pca_components = [3, 6, 9, 12, 15, 18, 21]\n",
    "    for n_components in pca_components:\n",
    "        print(\"n_components\", n_components)\n",
    "        result = use_pca(x_train, y_train, x_test, y_test, train_test_fn, n_components=n_components)\n",
    "        result[\"pca\"] = n_components\n",
    "        result[\"n_samples\"] = n_samples\n",
    "        result[\"classifier\"] = train_test_fn.__name__\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def train_test_all(n_samples):\n",
    "    tree_results = train_test(n_samples, train_test_decision_tree)\n",
    "    svm_results = train_test(n_samples, train_test_svm)\n",
    "    gnb_results = train_test(n_samples, train_test_gnb)\n",
    "    neighbors = train_test(n_samples, train_test_neighbors)\n",
    "    rnd_results = train_test(n_samples, train_test_random_forest)\n",
    "    return tree_results, svm_results, gnb_results, neighbors, rnd_results\n",
    "\n",
    "def train_test_samples(samples):\n",
    "    exps = []\n",
    "    for n_samples in samples:\n",
    "        tree_results, svm_results, gnb_results, neighbors, rnd_results = train_test_all(n_samples)\n",
    "        exps += tree_results\n",
    "        exps += svm_results\n",
    "        exps += gnb_results\n",
    "        exps += neighbors\n",
    "        exps += rnd_results\n",
    "    return exps\n",
    "\n",
    "exps = train_test_samples([50, 100, 200, 500, 1000, 2000, 5000])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exps_flat = [{\n",
    "    \"n_components\": exp.get(\"pca\"),\n",
    "    \"n_samples\": exp.get(\"n_samples\"),\n",
    "    \"classifier\": exp.get(\"classifier\"),\n",
    "    \"accuracy\": exp.get(\"accuracy\")\n",
    "} for exp in exps]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(exps_flat)\n",
    "\n",
    "maxes = df.groupby([\"classifier\", \"n_samples\"])[\"accuracy\"].max().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "maxes[\"classifier\"] = maxes[\"classifier\"].replace('train_test_decision_tree', \"Decision Tree\")\n",
    "maxes[\"classifier\"] = maxes[\"classifier\"].replace('train_test_gnb', \"Gaussian Naive Bayesian\")\n",
    "maxes[\"classifier\"] = maxes[\"classifier\"].replace('train_test_neighbors', \"Nearest Neighbours\")\n",
    "maxes[\"classifier\"] = maxes[\"classifier\"].replace('train_test_random_forest', \"Random Forest\")\n",
    "maxes[\"classifier\"] = maxes[\"classifier\"].replace('train_test_svm', \"SVM\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.lineplot(data=maxes, x=\"n_samples\", y=\"accuracy\", hue=\"classifier\")\n",
    "ax.set_title(\"Précision du modèle en fonction du nombre d'échantillon\")\n",
    "ax.set_ylabel(\"Précision\")\n",
    "ax.set_xlabel(\"Nombre d'échantillons\")\n",
    "plt.savefig(\"classification_acc_balanced.jpg\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}